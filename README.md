# InterviewLab
Check out the live site: InterviewLab.dev

Interviewing for software engineering jobs often comes down to two challenges: practicing effectively and getting meaningful feedback. I wanted to build a platform that solves both — a place where people can collaborate in real time, run code in the browser, and get AI-driven hints as they go. Before InterviewLab, I used a site called Codefile.io, but it was slow and laggy, which made mock interviews frustrating. Something like CoderPad works better but requires a paid subscription. That’s how InterviewLab was born — a free, real-time collaborative coding interview platform designed for practicing technical interviews.

# Building and Scaling
The code editor that powers the platform is written in TypeScript and uses Websockets. The backend is written in Go and storage is on a Postgres RDS instance. The biggest challenge with this project was making sure the app worked in a horizontally scaled environment. Within a single server, Go channels handle communication between connected users. To coordinate across servers, I used Redis Pub/Sub. Each coding session has its own Redis channel. When someone types or edits code, the update is sent to the backend through a WebSocket. The backend batches these edits and publishes updates to Redis every 200 milliseconds. Other servers subscribed to the same Redis channel receive those updates and forward them to their connected users, keeping everyone in sync.

One problem I ran into was that users joining an active room wouldn’t see the latest version of the code if someone was still typing. To fix this, I started hashing and saving the full room content in Redis every two seconds. When a new user joins, the server checks Redis and sends them the most recent snapshot before resuming live updates. This small change made synchronization much more reliable and eliminated most of the “stale view” issues I was seeing before.

The backend is on AWS ECS

# Extra Features
To make the editor feel like a real coding environment, I added a code execution feature powered by Piston API. I also integrated an AI assistant using a FastAPI service hosted on AWS Lambda. It connects to the OpenAI API to generate hints, feedback, and even new problem statements on demand.

# Considerations
I am not a big fan of having LLM-generated questions. I found that a lot of the questions generated by the AI feature aren't really the best when trying to study for interviews. Usually interviewers just paste a question from LeetCode (or a custom test bank for OOD questions). I plan on scraping questions and testcases from LC and adding them to the platform. This is more reflective of actual interview questions you might get and much more efficient token-wise. 
